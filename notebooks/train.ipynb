{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>text</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>interview</th>\n",
       "      <th>openness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J4GQm9j0JZ0.003.mp4</td>\n",
       "      <td>He's cutting it and then turn around and see t...</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>hes cutting turn around see end result im glad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zEyRyTnIw5I.005.mp4</td>\n",
       "      <td>Responsibility to house the organ I had been g...</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>responsibility house organ given needed tell g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nskJh7v6v1U.004.mp4</td>\n",
       "      <td>I actually got quite a few sets of black pens ...</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>actually got quite sets black pens year bought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6wHQsN5g2RM.000.mp4</td>\n",
       "      <td>I ate a lot. I'd like a lot of foods. I rememb...</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>ate lot id like lot foods remember favorite ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dQOeQYWIgm8.000.mp4</td>\n",
       "      <td>Now I'll ask you guys to leave a question in t...</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>ill ask guys leave question comments hopefully...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>Eh7WRYXVh9M.000.mp4</td>\n",
       "      <td>I got to see a lot, got to experience a lot. Y...</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>got see lot got experience lot yeah didnt know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>2q8orkMs2Jg.003.mp4</td>\n",
       "      <td>Really, really love my job, love the people I ...</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>really really love job love people work feel f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>F1lAPYh4t3U.000.mp4</td>\n",
       "      <td>I have a nine-to-five. I said this in my last ...</td>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.699029</td>\n",
       "      <td>ninetofive said last qa ninetofive per se prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>cxJ0u6r0-pU.001.mp4</td>\n",
       "      <td>You want to be working with and who you want t...</td>\n",
       "      <td>0.317757</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>want working want help bring anyone could get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>hfUH9Am-Izs.000.mp4</td>\n",
       "      <td>No, but, it's really hard to explain. It reall...</td>\n",
       "      <td>0.401869</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.429907</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>really hard explain really somebody asked feel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    video                                               text  \\\n",
       "0     J4GQm9j0JZ0.003.mp4  He's cutting it and then turn around and see t...   \n",
       "1     zEyRyTnIw5I.005.mp4  Responsibility to house the organ I had been g...   \n",
       "2     nskJh7v6v1U.004.mp4  I actually got quite a few sets of black pens ...   \n",
       "3     6wHQsN5g2RM.000.mp4  I ate a lot. I'd like a lot of foods. I rememb...   \n",
       "4     dQOeQYWIgm8.000.mp4  Now I'll ask you guys to leave a question in t...   \n",
       "...                   ...                                                ...   \n",
       "5995  Eh7WRYXVh9M.000.mp4  I got to see a lot, got to experience a lot. Y...   \n",
       "5996  2q8orkMs2Jg.003.mp4  Really, really love my job, love the people I ...   \n",
       "5997  F1lAPYh4t3U.000.mp4  I have a nine-to-five. I said this in my last ...   \n",
       "5998  cxJ0u6r0-pU.001.mp4  You want to be working with and who you want t...   \n",
       "5999  hfUH9Am-Izs.000.mp4  No, but, it's really hard to explain. It reall...   \n",
       "\n",
       "      extraversion  neuroticism  agreeableness  interview  openness  \\\n",
       "0         0.523364     0.552083       0.626374   0.504673  0.488889   \n",
       "1         0.345794     0.375000       0.472527   0.457944  0.366667   \n",
       "2         0.252336     0.291667       0.406593   0.373832  0.511111   \n",
       "3         0.457944     0.489583       0.505495   0.457944  0.377778   \n",
       "4         0.607477     0.489583       0.406593   0.570093  0.622222   \n",
       "...            ...          ...            ...        ...       ...   \n",
       "5995      0.523364     0.479167       0.626374   0.588785  0.544444   \n",
       "5996      0.728972     0.760417       0.582418   0.616822  0.822222   \n",
       "5997      0.700935     0.770833       0.747253   0.691589  0.788889   \n",
       "5998      0.317757     0.531250       0.582418   0.616822  0.588889   \n",
       "5999      0.401869     0.500000       0.461538   0.429907  0.588889   \n",
       "\n",
       "      conscientiousness                                  text_preprocessed  \n",
       "0              0.601942  hes cutting turn around see end result im glad...  \n",
       "1              0.582524  responsibility house organ given needed tell g...  \n",
       "2              0.485437  actually got quite sets black pens year bought...  \n",
       "3              0.398058  ate lot id like lot foods remember favorite ma...  \n",
       "4              0.621359  ill ask guys leave question comments hopefully...  \n",
       "...                 ...                                                ...  \n",
       "5995           0.621359  got see lot got experience lot yeah didnt know...  \n",
       "5996           0.524272  really really love job love people work feel f...  \n",
       "5997           0.699029  ninetofive said last qa ninetofive per se prob...  \n",
       "5998           0.679612  want working want help bring anyone could get ...  \n",
       "5999           0.543689  really hard explain really somebody asked feel...  \n",
       "\n",
       "[6000 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('environments/guivans_folder/data-2 (1).csv')\n",
    "# data = pd.read_csv('data-2 (1)-2.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>text</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>interview</th>\n",
       "      <th>openness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modNfUPt3F4.002.mp4</td>\n",
       "      <td>[inaudible 00:00:16] and then I will do the vo...</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>inaudible 000016 voice ill shots thats talking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h6LOjpCRXtY.005.mp4</td>\n",
       "      <td>Personality is A1, I like you. So that is all ...</td>\n",
       "      <td>0.439252</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.439252</td>\n",
       "      <td>0.411111</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>personality a1 like questions four minutes tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WER4ww680QQ.004.mp4</td>\n",
       "      <td>Ewe. But yeah, some people been asking me if I...</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>ewe yeah people asking still like one directio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4XnKouozXU.002.mp4</td>\n",
       "      <td>I am a makeup artist, I am an aesthetician, I ...</td>\n",
       "      <td>0.364486</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>makeup artist aesthetician someone also extrem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OEKg-Tvwcbk.002.mp4</td>\n",
       "      <td>Sucks. When he agrees, yeah. It just sucks bec...</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.383178</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>sucks agrees yeah sucks hot cant go walks girl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>3LAaFUSGvsU.000.mp4</td>\n",
       "      <td>Really qualified to. The guy who last week was...</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.494505</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>really qualified guy last week accountant week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>n2BuwHbdilY.000.mp4</td>\n",
       "      <td>Wearing scarfs on the second date. Okay, so no...</td>\n",
       "      <td>0.542056</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.549451</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>wearing scarfs second date okay hats scarfs pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>GcuoyJPO-KU.003.mp4</td>\n",
       "      <td>\"How do you manage to do things with someone? ...</td>\n",
       "      <td>0.551402</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.560440</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>manage things someone got used ive shapes acry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>uf_sIIw4zxY.004.mp4</td>\n",
       "      <td>-I sell. No. Sophie Loveland, \"Will you be pos...</td>\n",
       "      <td>0.514019</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.551402</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>sell sophie loveland posting video wedding you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>jd9_8OPxM3A.003.mp4</td>\n",
       "      <td>-to live together and to create a world where ...</td>\n",
       "      <td>0.560748</td>\n",
       "      <td>0.635417</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>live together create world coexist interested ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    video                                               text  \\\n",
       "0     modNfUPt3F4.002.mp4  [inaudible 00:00:16] and then I will do the vo...   \n",
       "1     h6LOjpCRXtY.005.mp4  Personality is A1, I like you. So that is all ...   \n",
       "2     WER4ww680QQ.004.mp4  Ewe. But yeah, some people been asking me if I...   \n",
       "3     c4XnKouozXU.002.mp4  I am a makeup artist, I am an aesthetician, I ...   \n",
       "4     OEKg-Tvwcbk.002.mp4  Sucks. When he agrees, yeah. It just sucks bec...   \n",
       "...                   ...                                                ...   \n",
       "1995  3LAaFUSGvsU.000.mp4  Really qualified to. The guy who last week was...   \n",
       "1996  n2BuwHbdilY.000.mp4  Wearing scarfs on the second date. Okay, so no...   \n",
       "1997  GcuoyJPO-KU.003.mp4  \"How do you manage to do things with someone? ...   \n",
       "1998  uf_sIIw4zxY.004.mp4  -I sell. No. Sophie Loveland, \"Will you be pos...   \n",
       "1999  jd9_8OPxM3A.003.mp4  -to live together and to create a world where ...   \n",
       "\n",
       "      extraversion  neuroticism  agreeableness  interview  openness  \\\n",
       "0         0.644860     0.593750       0.615385   0.616822  0.555556   \n",
       "1         0.439252     0.520833       0.417582   0.439252  0.411111   \n",
       "2         0.457944     0.312500       0.428571   0.373832  0.555556   \n",
       "3         0.364486     0.572917       0.527473   0.523364  0.322222   \n",
       "4         0.345794     0.468750       0.516484   0.383178  0.477778   \n",
       "...            ...          ...            ...        ...       ...   \n",
       "1995      0.570093     0.614583       0.494505   0.626168  0.577778   \n",
       "1996      0.542056     0.541667       0.549451   0.579439  0.666667   \n",
       "1997      0.551402     0.593750       0.560440   0.504673  0.644444   \n",
       "1998      0.514019     0.552083       0.461538   0.551402  0.733333   \n",
       "1999      0.560748     0.635417       0.725275   0.635514  0.666667   \n",
       "\n",
       "      conscientiousness                                  text_preprocessed  \n",
       "0              0.640777  inaudible 000016 voice ill shots thats talking...  \n",
       "1              0.572816  personality a1 like questions four minutes tod...  \n",
       "2              0.398058  ewe yeah people asking still like one directio...  \n",
       "3              0.553398  makeup artist aesthetician someone also extrem...  \n",
       "4              0.417476  sucks agrees yeah sucks hot cant go walks girl...  \n",
       "...                 ...                                                ...  \n",
       "1995           0.689320  really qualified guy last week accountant week...  \n",
       "1996           0.669903  wearing scarfs second date okay hats scarfs pl...  \n",
       "1997           0.572816  manage things someone got used ive shapes acry...  \n",
       "1998           0.572816  sell sophie loveland posting video wedding you...  \n",
       "1999           0.621359  live together create world coexist interested ...  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid = pd.read_csv('environments/data_valid.csv')\n",
    "# data_valid = pd.read_csv('data_valid.csv')\n",
    "data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_range(x, a, b, c, d):\n",
    "    return c + (d - c) * (x - a) / (b - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"Minej/bert-base-personality\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"Minej/bert-base-personality\").to(device)\n",
    "\n",
    "def personality_detection(text):\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    predictions = outputs.logits.squeeze().detach().numpy()\n",
    "\n",
    "    label_names = ['Extroversion', 'Neuroticism', 'Agreeableness', 'Conscientiousness', 'Openness']\n",
    "    result = {label_names[i]: predictions[i] for i in range(len(label_names))}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.squeeze()\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "    return {'MSES': mse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/environments/hack/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",            # Совпадает с evaluation_strategy\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=16,\n",
    "    weight_decay=0.01,\n",
    "    no_cuda=False,\n",
    "    load_best_model_at_end=True,      # Загрузка лучшей модели по окончании\n",
    "    metric_for_best_model=\"MSES\",     # Метрика, по которой выбирается лучшая модель\n",
    "    greater_is_better=False           # Установите в False, если метрика должна минимизироваться\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalityDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=85):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = dataframe['text'].map(str).tolist()\n",
    "        \n",
    "        # Получение 5 целевых значений для каждого примера\n",
    "        self.targets = dataframe[['extraversion', 'openness', 'conscientiousness', 'agreeableness', 'neuroticism']].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        # Токенизация\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(target, dtype=torch.float)  # Возвращаем 5-мерный тензор\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PersonalityDataset(data, tokenizer)\n",
    "test_dataset = PersonalityDataset(data_valid, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24000' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24000/24000 21:06, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.690781</td>\n",
       "      <td>0.281930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.689938</td>\n",
       "      <td>0.177870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>0.690090</td>\n",
       "      <td>0.253548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.690700</td>\n",
       "      <td>0.689790</td>\n",
       "      <td>0.212183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.695100</td>\n",
       "      <td>0.698528</td>\n",
       "      <td>0.055683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.690400</td>\n",
       "      <td>0.689979</td>\n",
       "      <td>0.208937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.689873</td>\n",
       "      <td>0.196855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.689910</td>\n",
       "      <td>0.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.689742</td>\n",
       "      <td>0.214472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.689670</td>\n",
       "      <td>0.210290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.689806</td>\n",
       "      <td>0.179293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.203180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.689681</td>\n",
       "      <td>0.210944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.689661</td>\n",
       "      <td>0.207676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.689650</td>\n",
       "      <td>0.207794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>0.689642</td>\n",
       "      <td>0.205196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=24000, training_loss=0.690584706624349, metrics={'train_runtime': 1266.2592, 'train_samples_per_second': 75.814, 'train_steps_per_second': 18.953, 'total_flos': 4193445395520000.0, 'train_loss': 0.690584706624349, 'epoch': 16.0})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model(\"./best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_personality_traits(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = outputs.logits.squeeze().cpu().numpy()  # Переводим на CPU и в numpy\n",
    "\n",
    "    traits = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Neuroticism\"]\n",
    "    return dict(zip(traits, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"./best_model\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Openness': 0.70907116,\n",
       " 'Conscientiousness': 1.2218435,\n",
       " 'Extraversion': 1.0589265,\n",
       " 'Agreeableness': 0.9691025,\n",
       " 'Neuroticism': 1.2008816}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_personality_traits(data.iloc[50].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:19, 104.21it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "for i, row in tqdm(data_valid.iterrows()):\n",
    "    preds.append(predict_personality_traits(str(row.text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.296347</td>\n",
       "      <td>0.690376</td>\n",
       "      <td>0.417417</td>\n",
       "      <td>0.472202</td>\n",
       "      <td>0.417897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.171134</td>\n",
       "      <td>0.258618</td>\n",
       "      <td>0.247354</td>\n",
       "      <td>0.335115</td>\n",
       "      <td>0.238763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.210255</td>\n",
       "      <td>0.305415</td>\n",
       "      <td>-0.008714</td>\n",
       "      <td>0.257146</td>\n",
       "      <td>0.145233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.326545</td>\n",
       "      <td>0.839618</td>\n",
       "      <td>0.514829</td>\n",
       "      <td>0.650687</td>\n",
       "      <td>0.672809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.316596</td>\n",
       "      <td>0.661830</td>\n",
       "      <td>0.388892</td>\n",
       "      <td>0.571474</td>\n",
       "      <td>0.508637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-0.141296</td>\n",
       "      <td>0.433503</td>\n",
       "      <td>0.398665</td>\n",
       "      <td>0.555429</td>\n",
       "      <td>0.308167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-0.288181</td>\n",
       "      <td>0.220752</td>\n",
       "      <td>0.192603</td>\n",
       "      <td>0.255032</td>\n",
       "      <td>-0.040319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-0.531018</td>\n",
       "      <td>-0.005694</td>\n",
       "      <td>-0.137100</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>-0.220955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.028742</td>\n",
       "      <td>0.482168</td>\n",
       "      <td>0.310379</td>\n",
       "      <td>0.424124</td>\n",
       "      <td>0.370328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-0.422438</td>\n",
       "      <td>-0.022456</td>\n",
       "      <td>-0.067443</td>\n",
       "      <td>0.161867</td>\n",
       "      <td>-0.130669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Openness  Conscientiousness  Extraversion  Agreeableness  Neuroticism\n",
       "0     0.296347           0.690376      0.417417       0.472202     0.417897\n",
       "1    -0.171134           0.258618      0.247354       0.335115     0.238763\n",
       "2    -0.210255           0.305415     -0.008714       0.257146     0.145233\n",
       "3     0.326545           0.839618      0.514829       0.650687     0.672809\n",
       "4     0.316596           0.661830      0.388892       0.571474     0.508637\n",
       "...        ...                ...           ...            ...          ...\n",
       "1995 -0.141296           0.433503      0.398665       0.555429     0.308167\n",
       "1996 -0.288181           0.220752      0.192603       0.255032    -0.040319\n",
       "1997 -0.531018          -0.005694     -0.137100       0.011455    -0.220955\n",
       "1998  0.028742           0.482168      0.310379       0.424124     0.370328\n",
       "1999 -0.422438          -0.022456     -0.067443       0.161867    -0.130669\n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.DataFrame(preds)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openness MSE: 0.038638479393160834 RMSE: 0.1965667301278648 MAE: 0.1568962927850261 -1.156436 0.89340734\n",
      "Conscientiousness MSE: 0.04564503655432543 RMSE: 0.21364699051080835 MAE: 0.17245063755491813 -0.6558855 1.3051943\n",
      "Extraversion MSE: 0.04243137137840986 RMSE: 0.20598876517521497 MAE: 0.16446037527513813 -0.7169265 1.2328148\n",
      "Agreeableness MSE: 0.038106205998554826 RMSE: 0.1952081094589946 MAE: 0.15564002225845536 -0.4751214 1.0410889\n",
      "Neuroticism MSE: 0.051474445789826774 RMSE: 0.22687980472009134 MAE: 0.1836191304961734 -0.90752506 1.1106781\n",
      "===============================================================================================\n",
      "MSE: 0.2162955391142777 RMSE: 1.038290399992974 MAE: 0.8330664583697112\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "s1 = 0\n",
    "s2 = 0\n",
    "\n",
    "for i in ['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']:\n",
    "    a = preds[i].min()\n",
    "    b = preds[i].max()\n",
    "    c = mean_squared_error(data_valid[i.lower()], preds[i].map(lambda x: map_range(x, a, b, 0, 1)))\n",
    "    d = c ** 0.5\n",
    "    e = mean_absolute_error(data_valid[i.lower()], preds[i].map(lambda x: map_range(x, a, b, 0, 1)))\n",
    "    print(i, \"MSE:\", c, \"RMSE:\", d, \"MAE:\", e, a, b)\n",
    "    s += c\n",
    "    s1 += d\n",
    "    s2 += e\n",
    "\n",
    "print(\"===============================================================================================\")\n",
    "print(\"MSE:\", s, \"RMSE:\", s1, \"MAE:\", s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
